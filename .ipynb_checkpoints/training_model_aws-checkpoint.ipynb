{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a notebook version of the training script for AWS to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_CNN import TextCNN\n",
    "from word_embeddings import embed_and_augment_data as em_aug\n",
    "from compiling_data import X_train, X_test, y_train, y_test\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "dictionary = {\"Company\": 0, \"Date\": 1, \"Location\": 2, \"Vessel\": 3}\n",
    "num_classes=4\n",
    "learning_rate=0.001\n",
    "batch_size=5\n",
    "decay_steps=1000\n",
    "decay_rate=0.95\n",
    "sequence_length=40\n",
    "embed_size=100\n",
    "is_training=True\n",
    "dropout_keep_prob=1.0\n",
    "filter_sizes=[4,5,6]\n",
    "num_filters=128\n",
    "\n",
    "textRNN=TextCNN(filter_sizes,num_filters,num_classes, learning_rate, batch_size, decay_steps, decay_rate,sequence_length,embed_size,is_training)\n",
    "\n",
    "n_epochs = 8\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for n in range(n_epochs):\n",
    "\n",
    "        for i in range(len(X_train) % batch_size):\n",
    "\n",
    "            input_x = np.stack(X_train.iloc[i*batch_size : batch_size*(i+1)].apply(em_aug).values)         # New augmentation every time\n",
    "            input_y = y_train.iloc[i*batch_size : batch_size*(i+1)].values\n",
    "            input_y = np.vectorize(dictionary.get)(input_y).reshape(-1)\n",
    "            loss,possibility,W_projection_value,_=sess.run([textRNN.loss_val,textRNN.possibility,textRNN.W_projection,textRNN.train_op],\n",
    "                                                    feed_dict={textRNN.X_in:input_x,textRNN.y_in:input_y,\n",
    "                                                                textRNN.dropout_keep_prob:dropout_keep_prob,textRNN.tst:False,\n",
    "                                                                textRNN.is_training_flag:is_training})\n",
    "\n",
    "        print(\"Batch {} of epoch {} completed, loss = {}\".format(i, n, loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
